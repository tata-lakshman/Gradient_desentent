{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ae36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc538e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bosten = pd.read_csv(r\"C:\\Users\\laksh\\Downloads\\boston1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8f5fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bosten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d4bc6",
   "metadata": {},
   "source": [
    "-DataSet description : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd98d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bosten[\"MEDV\"]\n",
    "x = bosten.drop(columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6a8b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e05ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe949b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "19e9ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "22a510d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2f6351d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, ...,\n",
       "        2.87234043e-01, 1.00000000e+00, 8.96799117e-02],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.53191489e-01, 1.00000000e+00, 2.04470199e-01],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.53191489e-01, 9.89737254e-01, 6.34657837e-02],\n",
       "       ...,\n",
       "       [6.11892474e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 1.00000000e+00, 1.07891832e-01],\n",
       "       [1.16072990e-03, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 9.91300620e-01, 1.31070640e-01],\n",
       "       [4.61841693e-04, 0.00000000e+00, 4.20454545e-01, ...,\n",
       "        8.93617021e-01, 1.00000000e+00, 1.69701987e-01]], shape=(506, 13))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2d979a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.125, 0.125, 0.125,\n",
       "       0.125, 0.125, 0.125, 0.125, 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.75 , 0.75 , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.21 , 0.21 , 0.21 , 0.21 ,\n",
       "       0.75 , 0.9  , 0.85 , 1.   , 0.25 , 0.25 , 0.25 , 0.25 , 0.25 ,\n",
       "       0.25 , 0.175, 0.8  , 0.8  , 0.125, 0.125, 0.125, 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.25 ,\n",
       "       0.25 , 0.25 , 0.25 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.28 , 0.28 , 0.28 , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.45 , 0.45 ,\n",
       "       0.45 , 0.45 , 0.45 , 0.45 , 0.6  , 0.6  , 0.8  , 0.8  , 0.8  ,\n",
       "       0.8  , 0.95 , 0.95 , 0.825, 0.825, 0.95 , 0.95 , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.3  , 0.3  , 0.3  , 0.3  , 0.3  ,\n",
       "       0.3  , 0.22 , 0.22 , 0.22 , 0.22 , 0.22 , 0.22 , 0.22 , 0.22 ,\n",
       "       0.22 , 0.22 , 0.8  , 0.8  , 0.9  , 0.2  , 0.2  , 0.2  , 0.2  ,\n",
       "       0.2  , 0.2  , 0.2  , 0.2  , 0.2  , 0.2  , 0.2  , 0.2  , 0.2  ,\n",
       "       0.2  , 0.2  , 0.2  , 0.2  , 0.4  , 0.4  , 0.4  , 0.4  , 0.4  ,\n",
       "       0.2  , 0.2  , 0.2  , 0.2  , 0.9  , 0.9  , 0.55 , 0.8  , 0.525,\n",
       "       0.525, 0.525, 0.8  , 0.8  , 0.8  , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.7  , 0.7  , 0.7  , 0.34 , 0.34 , 0.34 , 0.33 , 0.33 ,\n",
       "       0.33 , 0.33 , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.35 , 0.35 ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.35 ,\n",
       "       0.   , 0.55 , 0.55 , 0.   , 0.   , 0.85 , 0.8  , 0.4  , 0.4  ,\n",
       "       0.6  , 0.6  , 0.9  , 0.8  , 0.8  , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   ])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "06171407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(x)[:,1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c7e1eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit_transform(x)[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3a689c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scalar.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c0ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MinMaxScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.MinMaxScaler.html#:~:text=feature_range,-tuple%20%28min%2C%20max%29%2C%20default%3D%280%2C%201%29\">\n",
       "            feature_range\n",
       "            <span class=\"param-doc-description\">feature_range: tuple (min, max), default=(0, 1)<br><br>Desired range of transformed data.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">(0, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.MinMaxScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>Set to False to perform inplace row normalization and avoid a<br>copy (if the input is already a numpy array).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('clip',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.MinMaxScaler.html#:~:text=clip,-bool%2C%20default%3DFalse\">\n",
       "            clip\n",
       "            <span class=\"param-doc-description\">clip: bool, default=False<br><br>Set to True to clip transformed values of held-out data to<br>provided `feature_range`.<br>Since this parameter will clip values, `inverse_transform` may not<br>be able to restore the original data.<br><br>.. note::<br>    Setting `clip=True` does not prevent feature drift (a distribution<br>    shift between training and test data). The transformed values are clipped<br>    to the `feature_range`, which helps avoid unintended behavior in models<br>    sensitive to out-of-range inputs (e.g. linear models). Use with care,<br>    as clipping can distort the distribution of test data.<br><br>.. versionadded:: 0.24</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scalar_target = MinMaxScaler()\n",
    "scalar.fit(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "28b0014b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42222222],\n",
       "       [0.36888889],\n",
       "       [0.66      ],\n",
       "       [0.63111111],\n",
       "       [0.69333333],\n",
       "       [0.52666667],\n",
       "       [0.39777778],\n",
       "       [0.49111111],\n",
       "       [0.25555556],\n",
       "       [0.30888889],\n",
       "       [0.22222222],\n",
       "       [0.30888889],\n",
       "       [0.37111111],\n",
       "       [0.34222222],\n",
       "       [0.29333333],\n",
       "       [0.33111111],\n",
       "       [0.40222222],\n",
       "       [0.27777778],\n",
       "       [0.33777778],\n",
       "       [0.29333333],\n",
       "       [0.19111111],\n",
       "       [0.32444444],\n",
       "       [0.22666667],\n",
       "       [0.21111111],\n",
       "       [0.23555556],\n",
       "       [0.19777778],\n",
       "       [0.25777778],\n",
       "       [0.21777778],\n",
       "       [0.29777778],\n",
       "       [0.35555556],\n",
       "       [0.17111111],\n",
       "       [0.21111111],\n",
       "       [0.18222222],\n",
       "       [0.18      ],\n",
       "       [0.18888889],\n",
       "       [0.30888889],\n",
       "       [0.33333333],\n",
       "       [0.35555556],\n",
       "       [0.43777778],\n",
       "       [0.57333333],\n",
       "       [0.66444444],\n",
       "       [0.48      ],\n",
       "       [0.45111111],\n",
       "       [0.43777778],\n",
       "       [0.36      ],\n",
       "       [0.31777778],\n",
       "       [0.33333333],\n",
       "       [0.25777778],\n",
       "       [0.20888889],\n",
       "       [0.32      ],\n",
       "       [0.32666667],\n",
       "       [0.34444444],\n",
       "       [0.44444444],\n",
       "       [0.40888889],\n",
       "       [0.30888889],\n",
       "       [0.67555556],\n",
       "       [0.43777778],\n",
       "       [0.59111111],\n",
       "       [0.40666667],\n",
       "       [0.32444444],\n",
       "       [0.30444444],\n",
       "       [0.24444444],\n",
       "       [0.38222222],\n",
       "       [0.44444444],\n",
       "       [0.62222222],\n",
       "       [0.41111111],\n",
       "       [0.32      ],\n",
       "       [0.37777778],\n",
       "       [0.27555556],\n",
       "       [0.35333333],\n",
       "       [0.42666667],\n",
       "       [0.37111111],\n",
       "       [0.39555556],\n",
       "       [0.40888889],\n",
       "       [0.42444444],\n",
       "       [0.36444444],\n",
       "       [0.33333333],\n",
       "       [0.35111111],\n",
       "       [0.36      ],\n",
       "       [0.34      ],\n",
       "       [0.51111111],\n",
       "       [0.42      ],\n",
       "       [0.44      ],\n",
       "       [0.39777778],\n",
       "       [0.42      ],\n",
       "       [0.48      ],\n",
       "       [0.38888889],\n",
       "       [0.38222222],\n",
       "       [0.41333333],\n",
       "       [0.52666667],\n",
       "       [0.39111111],\n",
       "       [0.37777778],\n",
       "       [0.39777778],\n",
       "       [0.44444444],\n",
       "       [0.34666667],\n",
       "       [0.52      ],\n",
       "       [0.36444444],\n",
       "       [0.74888889],\n",
       "       [0.86222222],\n",
       "       [0.62666667],\n",
       "       [0.5       ],\n",
       "       [0.47777778],\n",
       "       [0.30222222],\n",
       "       [0.31777778],\n",
       "       [0.33555556],\n",
       "       [0.32222222],\n",
       "       [0.32222222],\n",
       "       [0.34222222],\n",
       "       [0.32888889],\n",
       "       [0.32      ],\n",
       "       [0.37111111],\n",
       "       [0.39555556],\n",
       "       [0.30666667],\n",
       "       [0.30444444],\n",
       "       [0.3       ],\n",
       "       [0.29555556],\n",
       "       [0.36      ],\n",
       "       [0.31555556],\n",
       "       [0.34222222],\n",
       "       [0.31777778],\n",
       "       [0.37777778],\n",
       "       [0.34      ],\n",
       "       [0.34444444],\n",
       "       [0.27333333],\n",
       "       [0.30666667],\n",
       "       [0.36444444],\n",
       "       [0.23777778],\n",
       "       [0.24888889],\n",
       "       [0.28888889],\n",
       "       [0.20666667],\n",
       "       [0.31555556],\n",
       "       [0.32444444],\n",
       "       [0.4       ],\n",
       "       [0.29777778],\n",
       "       [0.23555556],\n",
       "       [0.29111111],\n",
       "       [0.27555556],\n",
       "       [0.26888889],\n",
       "       [0.18444444],\n",
       "       [0.28444444],\n",
       "       [0.2       ],\n",
       "       [0.20888889],\n",
       "       [0.18666667],\n",
       "       [0.23555556],\n",
       "       [0.15111111],\n",
       "       [0.19555556],\n",
       "       [0.23555556],\n",
       "       [0.21333333],\n",
       "       [0.28444444],\n",
       "       [0.23111111],\n",
       "       [0.36666667],\n",
       "       [0.32444444],\n",
       "       [0.22888889],\n",
       "       [0.32      ],\n",
       "       [0.26666667],\n",
       "       [0.23555556],\n",
       "       [0.18      ],\n",
       "       [0.80666667],\n",
       "       [0.42888889],\n",
       "       [0.40666667],\n",
       "       [0.48888889],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.39333333],\n",
       "       [0.44444444],\n",
       "       [1.        ],\n",
       "       [0.41777778],\n",
       "       [0.41777778],\n",
       "       [0.38444444],\n",
       "       [0.27555556],\n",
       "       [0.31333333],\n",
       "       [0.40222222],\n",
       "       [0.41333333],\n",
       "       [0.39111111],\n",
       "       [0.54222222],\n",
       "       [0.40444444],\n",
       "       [0.43555556],\n",
       "       [0.55333333],\n",
       "       [0.71555556],\n",
       "       [0.77333333],\n",
       "       [0.69333333],\n",
       "       [0.73111111],\n",
       "       [0.61111111],\n",
       "       [0.47555556],\n",
       "       [0.54666667],\n",
       "       [1.        ],\n",
       "       [0.6       ],\n",
       "       [0.55111111],\n",
       "       [0.66444444],\n",
       "       [0.71111111],\n",
       "       [0.56666667],\n",
       "       [0.69777778],\n",
       "       [0.58      ],\n",
       "       [0.53555556],\n",
       "       [1.        ],\n",
       "       [0.62888889],\n",
       "       [0.56222222],\n",
       "       [0.65777778],\n",
       "       [0.66444444],\n",
       "       [0.62      ],\n",
       "       [0.42444444],\n",
       "       [0.82888889],\n",
       "       [0.96666667],\n",
       "       [1.        ],\n",
       "       [0.39111111],\n",
       "       [0.43111111],\n",
       "       [0.38888889],\n",
       "       [0.43111111],\n",
       "       [0.33333333],\n",
       "       [0.37111111],\n",
       "       [0.31777778],\n",
       "       [0.38666667],\n",
       "       [0.51333333],\n",
       "       [0.41555556],\n",
       "       [0.44444444],\n",
       "       [0.40666667],\n",
       "       [0.52666667],\n",
       "       [0.36666667],\n",
       "       [0.4       ],\n",
       "       [0.48222222],\n",
       "       [0.37111111],\n",
       "       [0.5       ],\n",
       "       [0.55777778],\n",
       "       [0.88444444],\n",
       "       [1.        ],\n",
       "       [0.72444444],\n",
       "       [0.59111111],\n",
       "       [0.92666667],\n",
       "       [0.58888889],\n",
       "       [0.42888889],\n",
       "       [0.59333333],\n",
       "       [0.81555556],\n",
       "       [0.96222222],\n",
       "       [0.53333333],\n",
       "       [0.42222222],\n",
       "       [0.44666667],\n",
       "       [0.58888889],\n",
       "       [0.41555556],\n",
       "       [0.40666667],\n",
       "       [0.37777778],\n",
       "       [0.33555556],\n",
       "       [0.38222222],\n",
       "       [0.41555556],\n",
       "       [0.28      ],\n",
       "       [0.3       ],\n",
       "       [0.42888889],\n",
       "       [0.34444444],\n",
       "       [0.43333333],\n",
       "       [0.47111111],\n",
       "       [0.43111111],\n",
       "       [0.44      ],\n",
       "       [0.54666667],\n",
       "       [0.84      ],\n",
       "       [0.37555556],\n",
       "       [0.35333333],\n",
       "       [0.86666667],\n",
       "       [1.        ],\n",
       "       [0.68888889],\n",
       "       [0.55777778],\n",
       "       [0.64      ],\n",
       "       [0.84666667],\n",
       "       [0.97333333],\n",
       "       [0.57777778],\n",
       "       [0.7       ],\n",
       "       [0.39555556],\n",
       "       [0.57111111],\n",
       "       [1.        ],\n",
       "       [0.85555556],\n",
       "       [0.34888889],\n",
       "       [0.35777778],\n",
       "       [0.44888889],\n",
       "       [0.43111111],\n",
       "       [0.67111111],\n",
       "       [0.60888889],\n",
       "       [0.6       ],\n",
       "       [0.62666667],\n",
       "       [0.62444444],\n",
       "       [0.53555556],\n",
       "       [0.66888889],\n",
       "       [0.89777778],\n",
       "       [0.67555556],\n",
       "       [0.91111111],\n",
       "       [1.        ],\n",
       "       [0.60444444],\n",
       "       [0.37777778],\n",
       "       [0.33555556],\n",
       "       [0.40444444],\n",
       "       [0.38444444],\n",
       "       [0.44      ],\n",
       "       [0.52222222],\n",
       "       [0.71777778],\n",
       "       [0.50888889],\n",
       "       [0.42      ],\n",
       "       [0.37111111],\n",
       "       [0.52444444],\n",
       "       [0.49111111],\n",
       "       [0.34      ],\n",
       "       [0.38888889],\n",
       "       [0.53333333],\n",
       "       [0.44      ],\n",
       "       [0.37777778],\n",
       "       [0.47555556],\n",
       "       [0.62444444],\n",
       "       [0.69111111],\n",
       "       [0.52      ],\n",
       "       [0.63111111],\n",
       "       [0.51555556],\n",
       "       [0.39555556],\n",
       "       [0.34      ],\n",
       "       [0.24666667],\n",
       "       [0.38      ],\n",
       "       [0.32      ],\n",
       "       [0.36888889],\n",
       "       [0.41777778],\n",
       "       [0.24888889],\n",
       "       [0.28444444],\n",
       "       [0.32888889],\n",
       "       [0.40222222],\n",
       "       [0.35555556],\n",
       "       [0.41777778],\n",
       "       [0.40222222],\n",
       "       [0.34222222],\n",
       "       [0.3       ],\n",
       "       [0.44444444],\n",
       "       [0.43555556],\n",
       "       [0.4       ],\n",
       "       [0.38222222],\n",
       "       [0.31777778],\n",
       "       [0.39111111],\n",
       "       [0.32888889],\n",
       "       [0.26888889],\n",
       "       [0.32      ],\n",
       "       [0.38222222],\n",
       "       [0.34888889],\n",
       "       [0.35777778],\n",
       "       [0.32222222],\n",
       "       [0.3       ],\n",
       "       [0.34666667],\n",
       "       [0.31111111],\n",
       "       [0.30444444],\n",
       "       [0.61555556],\n",
       "       [0.25555556],\n",
       "       [0.42      ],\n",
       "       [0.58222222],\n",
       "       [0.27777778],\n",
       "       [0.27111111],\n",
       "       [0.40222222],\n",
       "       [0.43333333],\n",
       "       [0.48      ],\n",
       "       [0.39777778],\n",
       "       [0.42444444],\n",
       "       [0.30222222],\n",
       "       [0.55777778],\n",
       "       [0.29333333],\n",
       "       [0.34666667],\n",
       "       [0.28444444],\n",
       "       [0.37111111],\n",
       "       [0.39333333],\n",
       "       [0.39111111],\n",
       "       [0.44444444],\n",
       "       [0.33111111],\n",
       "       [0.35111111],\n",
       "       [0.26222222],\n",
       "       [0.37555556],\n",
       "       [0.5       ],\n",
       "       [0.37555556],\n",
       "       [0.40222222],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.19555556],\n",
       "       [0.19555556],\n",
       "       [0.22222222],\n",
       "       [0.19777778],\n",
       "       [0.18444444],\n",
       "       [0.18      ],\n",
       "       [0.11555556],\n",
       "       [0.12      ],\n",
       "       [0.13111111],\n",
       "       [0.14      ],\n",
       "       [0.16222222],\n",
       "       [0.08444444],\n",
       "       [0.04888889],\n",
       "       [0.12222222],\n",
       "       [0.05333333],\n",
       "       [0.11555556],\n",
       "       [0.14444444],\n",
       "       [0.22444444],\n",
       "       [0.40444444],\n",
       "       [0.10444444],\n",
       "       [0.19555556],\n",
       "       [0.17111111],\n",
       "       [0.18      ],\n",
       "       [0.16666667],\n",
       "       [0.07777778],\n",
       "       [0.        ],\n",
       "       [0.02888889],\n",
       "       [0.01333333],\n",
       "       [0.04888889],\n",
       "       [0.15777778],\n",
       "       [0.07333333],\n",
       "       [0.07777778],\n",
       "       [0.        ],\n",
       "       [0.15333333],\n",
       "       [0.50888889],\n",
       "       [0.27111111],\n",
       "       [0.5       ],\n",
       "       [0.22222222],\n",
       "       [0.27111111],\n",
       "       [0.28666667],\n",
       "       [0.25111111],\n",
       "       [0.04444444],\n",
       "       [0.04888889],\n",
       "       [0.05555556],\n",
       "       [0.12      ],\n",
       "       [0.08444444],\n",
       "       [0.07555556],\n",
       "       [0.26      ],\n",
       "       [0.20444444],\n",
       "       [0.35111111],\n",
       "       [0.18666667],\n",
       "       [0.14888889],\n",
       "       [0.07333333],\n",
       "       [0.11555556],\n",
       "       [0.13111111],\n",
       "       [0.13333333],\n",
       "       [0.1       ],\n",
       "       [0.21111111],\n",
       "       [0.20222222],\n",
       "       [0.24666667],\n",
       "       [0.20666667],\n",
       "       [0.14888889],\n",
       "       [0.18666667],\n",
       "       [0.10222222],\n",
       "       [0.08222222],\n",
       "       [0.07555556],\n",
       "       [0.17333333],\n",
       "       [0.12222222],\n",
       "       [0.26888889],\n",
       "       [0.29777778],\n",
       "       [0.23111111],\n",
       "       [0.12888889],\n",
       "       [0.15111111],\n",
       "       [0.22      ],\n",
       "       [0.16888889],\n",
       "       [0.20222222],\n",
       "       [0.17777778],\n",
       "       [0.18666667],\n",
       "       [0.22666667],\n",
       "       [0.24666667],\n",
       "       [0.28444444],\n",
       "       [0.22      ],\n",
       "       [0.20222222],\n",
       "       [0.17111111],\n",
       "       [0.18888889],\n",
       "       [0.22      ],\n",
       "       [0.33333333],\n",
       "       [0.25333333],\n",
       "       [0.28222222],\n",
       "       [0.32222222],\n",
       "       [0.33777778],\n",
       "       [0.36444444],\n",
       "       [0.33111111],\n",
       "       [0.31111111],\n",
       "       [0.31333333],\n",
       "       [0.31333333],\n",
       "       [0.33555556],\n",
       "       [0.33111111],\n",
       "       [0.32444444],\n",
       "       [0.40444444],\n",
       "       [0.55111111],\n",
       "       [0.19555556],\n",
       "       [0.18444444],\n",
       "       [0.26      ],\n",
       "       [0.15555556],\n",
       "       [0.21333333],\n",
       "       [0.36444444],\n",
       "       [0.4       ],\n",
       "       [0.41555556],\n",
       "       [0.44444444],\n",
       "       [0.37333333],\n",
       "       [0.34666667],\n",
       "       [0.36      ],\n",
       "       [0.31333333],\n",
       "       [0.34666667],\n",
       "       [0.22666667],\n",
       "       [0.04444444],\n",
       "       [0.06888889],\n",
       "       [0.19111111],\n",
       "       [0.33555556],\n",
       "       [0.37333333],\n",
       "       [0.43333333],\n",
       "       [0.40222222],\n",
       "       [0.32666667],\n",
       "       [0.29555556],\n",
       "       [0.36      ],\n",
       "       [0.27777778],\n",
       "       [0.26222222],\n",
       "       [0.38666667],\n",
       "       [0.34666667],\n",
       "       [0.42      ],\n",
       "       [0.37777778],\n",
       "       [0.15333333]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "110726fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.transform(y.reshape(-1,1)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6cefde80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.transform(y.reshape(-1,1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "940a3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = scalar.transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c66f4",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8aa25d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y.flatten(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2b4afe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339, 13)\n",
      "(339,)\n",
      "(167, 13)\n",
      "(167,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160abbdb",
   "metadata": {},
   "source": [
    "### Model(NN) Building\n",
    "3 Steps:\n",
    "1. Model Definition:\n",
    "    - Architecture of the model (#HL, #Nodes, #Activation Functions)\n",
    "2. Model Compilation \n",
    "    - Optimization Algorithm (SGD, ADAM, ..),Learning Rate,Cost Function\n",
    "3. Training\n",
    "    - Epochs / Iterations, DataSets (Test and Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "45aba83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam,Adagrad,Adadelta\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(13,))) #No computation here-This is not mandatory\n",
    "model.add(Dense(units=4 , activation='relu')) #HL\n",
    "model.add(Dense(units=1)) #output Layer #w1x1+w2x2+w3x3+... (only 1 unit here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e47e5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "model.compile(optimizer=Adam(learning_rate=0.003),loss=\"mean_squared_error\",metrics=[RootMeanSquaredError()])\n",
    "# model.compile(optimizer=Adadelta(learning_rate=0.3),loss=\"mean_squared_error\",metrics=[RootMeanSquaredError()])#444 not the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "63be1281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4586 - root_mean_squared_error: 0.6772 - val_loss: 0.2836 - val_root_mean_squared_error: 0.5326\n",
      "Epoch 2/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1739 - root_mean_squared_error: 0.4170 - val_loss: 0.1281 - val_root_mean_squared_error: 0.3579\n",
      "Epoch 3/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1139 - root_mean_squared_error: 0.3374 - val_loss: 0.1055 - val_root_mean_squared_error: 0.3248\n",
      "Epoch 4/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1053 - root_mean_squared_error: 0.3245 - val_loss: 0.0927 - val_root_mean_squared_error: 0.3045\n",
      "Epoch 5/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0914 - root_mean_squared_error: 0.3023 - val_loss: 0.0819 - val_root_mean_squared_error: 0.2862\n",
      "Epoch 6/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0816 - root_mean_squared_error: 0.2857 - val_loss: 0.0758 - val_root_mean_squared_error: 0.2753\n",
      "Epoch 7/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0746 - root_mean_squared_error: 0.2732 - val_loss: 0.0689 - val_root_mean_squared_error: 0.2624\n",
      "Epoch 8/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0688 - root_mean_squared_error: 0.2622 - val_loss: 0.0623 - val_root_mean_squared_error: 0.2497\n",
      "Epoch 9/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0643 - root_mean_squared_error: 0.2536 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2406\n",
      "Epoch 10/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0611 - root_mean_squared_error: 0.2471 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350\n",
      "Epoch 11/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0580 - root_mean_squared_error: 0.2408 - val_loss: 0.0522 - val_root_mean_squared_error: 0.2285\n",
      "Epoch 12/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0555 - root_mean_squared_error: 0.2356 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2240\n",
      "Epoch 13/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0534 - root_mean_squared_error: 0.2310 - val_loss: 0.0479 - val_root_mean_squared_error: 0.2189\n",
      "Epoch 14/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0515 - root_mean_squared_error: 0.2270 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2158\n",
      "Epoch 15/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0499 - root_mean_squared_error: 0.2233 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2106\n",
      "Epoch 16/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0481 - root_mean_squared_error: 0.2192 - val_loss: 0.0433 - val_root_mean_squared_error: 0.2080\n",
      "Epoch 17/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0465 - root_mean_squared_error: 0.2155 - val_loss: 0.0418 - val_root_mean_squared_error: 0.2045\n",
      "Epoch 18/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0450 - root_mean_squared_error: 0.2122 - val_loss: 0.0406 - val_root_mean_squared_error: 0.2016\n",
      "Epoch 19/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0437 - root_mean_squared_error: 0.2091 - val_loss: 0.0393 - val_root_mean_squared_error: 0.1983\n",
      "Epoch 20/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0423 - root_mean_squared_error: 0.2057 - val_loss: 0.0381 - val_root_mean_squared_error: 0.1952\n",
      "Epoch 21/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0411 - root_mean_squared_error: 0.2028 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1920\n",
      "Epoch 22/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0399 - root_mean_squared_error: 0.1999 - val_loss: 0.0360 - val_root_mean_squared_error: 0.1897\n",
      "Epoch 23/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0389 - root_mean_squared_error: 0.1972 - val_loss: 0.0350 - val_root_mean_squared_error: 0.1872\n",
      "Epoch 24/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
      "Epoch 25/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0367 - root_mean_squared_error: 0.1915 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1819\n",
      "Epoch 26/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0356 - root_mean_squared_error: 0.1886 - val_loss: 0.0322 - val_root_mean_squared_error: 0.1794\n",
      "Epoch 27/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0347 - root_mean_squared_error: 0.1863 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1774\n",
      "Epoch 28/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
      "Epoch 29/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0328 - root_mean_squared_error: 0.1812 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1723\n",
      "Epoch 30/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0320 - root_mean_squared_error: 0.1788 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
      "Epoch 31/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0314 - root_mean_squared_error: 0.1771 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
      "Epoch 32/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0302 - root_mean_squared_error: 0.1739 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
      "Epoch 33/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0296 - root_mean_squared_error: 0.1722 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1632\n",
      "Epoch 34/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0290 - root_mean_squared_error: 0.1702 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1615\n",
      "Epoch 35/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599\n",
      "Epoch 36/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0247 - val_root_mean_squared_error: 0.1572\n",
      "Epoch 37/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0268 - root_mean_squared_error: 0.1638 - val_loss: 0.0240 - val_root_mean_squared_error: 0.1550\n",
      "Epoch 38/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0261 - root_mean_squared_error: 0.1615 - val_loss: 0.0236 - val_root_mean_squared_error: 0.1537\n",
      "Epoch 39/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0254 - root_mean_squared_error: 0.1594 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1517\n",
      "Epoch 40/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0250 - root_mean_squared_error: 0.1582 - val_loss: 0.0224 - val_root_mean_squared_error: 0.1497\n",
      "Epoch 41/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0247 - root_mean_squared_error: 0.1572 - val_loss: 0.0222 - val_root_mean_squared_error: 0.1490\n",
      "Epoch 42/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534 - val_loss: 0.0213 - val_root_mean_squared_error: 0.1459\n",
      "Epoch 43/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0231 - root_mean_squared_error: 0.1520 - val_loss: 0.0208 - val_root_mean_squared_error: 0.1441\n",
      "Epoch 44/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0224 - root_mean_squared_error: 0.1495 - val_loss: 0.0205 - val_root_mean_squared_error: 0.1431\n",
      "Epoch 45/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1409\n",
      "Epoch 46/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0195 - val_root_mean_squared_error: 0.1395\n",
      "Epoch 47/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0208 - root_mean_squared_error: 0.1441 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1378\n",
      "Epoch 48/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0185 - val_root_mean_squared_error: 0.1361\n",
      "Epoch 49/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0201 - root_mean_squared_error: 0.1419 - val_loss: 0.0182 - val_root_mean_squared_error: 0.1349\n",
      "Epoch 50/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0195 - root_mean_squared_error: 0.1397 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1333\n",
      "Epoch 51/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0191 - root_mean_squared_error: 0.1383 - val_loss: 0.0173 - val_root_mean_squared_error: 0.1316\n",
      "Epoch 52/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - root_mean_squared_error: 0.1366 - val_loss: 0.0169 - val_root_mean_squared_error: 0.1301\n",
      "Epoch 53/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0183 - root_mean_squared_error: 0.1353 - val_loss: 0.0166 - val_root_mean_squared_error: 0.1287\n",
      "Epoch 54/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0179 - root_mean_squared_error: 0.1338 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
      "Epoch 55/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0160 - val_root_mean_squared_error: 0.1264\n",
      "Epoch 56/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0172 - root_mean_squared_error: 0.1313 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1250\n",
      "Epoch 57/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0152 - val_root_mean_squared_error: 0.1234\n",
      "Epoch 58/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1223\n",
      "Epoch 59/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0163 - root_mean_squared_error: 0.1277 - val_loss: 0.0146 - val_root_mean_squared_error: 0.1210\n",
      "Epoch 60/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0160 - root_mean_squared_error: 0.1266 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1202\n",
      "Epoch 61/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0158 - root_mean_squared_error: 0.1257 - val_loss: 0.0142 - val_root_mean_squared_error: 0.1191\n",
      "Epoch 62/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0155 - root_mean_squared_error: 0.1245 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1182\n",
      "Epoch 63/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0152 - root_mean_squared_error: 0.1235 - val_loss: 0.0138 - val_root_mean_squared_error: 0.1173\n",
      "Epoch 64/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0151 - root_mean_squared_error: 0.1229 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1163\n",
      "Epoch 65/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0148 - root_mean_squared_error: 0.1218 - val_loss: 0.0134 - val_root_mean_squared_error: 0.1156\n",
      "Epoch 66/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - root_mean_squared_error: 0.1207 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1145\n",
      "Epoch 67/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0144 - root_mean_squared_error: 0.1202 - val_loss: 0.0129 - val_root_mean_squared_error: 0.1137\n",
      "Epoch 68/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0142 - root_mean_squared_error: 0.1192 - val_loss: 0.0128 - val_root_mean_squared_error: 0.1129\n",
      "Epoch 69/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0127 - val_root_mean_squared_error: 0.1127\n",
      "Epoch 70/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - root_mean_squared_error: 0.1177 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1117\n",
      "Epoch 71/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0137 - root_mean_squared_error: 0.1169 - val_loss: 0.0124 - val_root_mean_squared_error: 0.1113\n",
      "Epoch 72/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 - root_mean_squared_error: 0.1162 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1108\n",
      "Epoch 73/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0134 - root_mean_squared_error: 0.1156 - val_loss: 0.0121 - val_root_mean_squared_error: 0.1099\n",
      "Epoch 74/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0132 - root_mean_squared_error: 0.1150 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1094\n",
      "Epoch 75/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0131 - root_mean_squared_error: 0.1146 - val_loss: 0.0118 - val_root_mean_squared_error: 0.1086\n",
      "Epoch 76/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - root_mean_squared_error: 0.1140 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1079\n",
      "Epoch 77/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0128 - root_mean_squared_error: 0.1132 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1081\n",
      "Epoch 78/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0127 - root_mean_squared_error: 0.1127 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1074\n",
      "Epoch 79/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0126 - root_mean_squared_error: 0.1124 - val_loss: 0.0115 - val_root_mean_squared_error: 0.1070\n",
      "Epoch 80/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - root_mean_squared_error: 0.1117 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1065\n",
      "Epoch 81/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1061\n",
      "Epoch 82/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - root_mean_squared_error: 0.1113 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 83/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - root_mean_squared_error: 0.1116 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
      "Epoch 84/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1066\n",
      "Epoch 85/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1094 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1047\n",
      "Epoch 86/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - root_mean_squared_error: 0.1096 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1043\n",
      "Epoch 87/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0118 - root_mean_squared_error: 0.1084 - val_loss: 0.0109 - val_root_mean_squared_error: 0.1046\n",
      "Epoch 88/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0117 - root_mean_squared_error: 0.1082 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1040\n",
      "Epoch 89/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0117 - root_mean_squared_error: 0.1080 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1034\n",
      "Epoch 90/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0116 - root_mean_squared_error: 0.1077 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
      "Epoch 91/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - root_mean_squared_error: 0.1080 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
      "Epoch 92/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1032\n",
      "Epoch 93/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - root_mean_squared_error: 0.1066 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
      "Epoch 94/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0114 - root_mean_squared_error: 0.1066 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1028\n",
      "Epoch 95/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0112 - root_mean_squared_error: 0.1060 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1024\n",
      "Epoch 96/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0113 - root_mean_squared_error: 0.1061 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 97/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0111 - root_mean_squared_error: 0.1055 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 98/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0112 - root_mean_squared_error: 0.1057 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1016\n",
      "Epoch 99/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - root_mean_squared_error: 0.1050 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1020\n",
      "Epoch 100/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0110 - root_mean_squared_error: 0.1050 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 101/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0110 - root_mean_squared_error: 0.1048 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1008\n",
      "Epoch 102/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - root_mean_squared_error: 0.1043 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 103/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - root_mean_squared_error: 0.1052 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1006\n",
      "Epoch 104/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0111 - root_mean_squared_error: 0.1056 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1005\n",
      "Epoch 105/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0108 - root_mean_squared_error: 0.1042 - val_loss: 0.0103 - val_root_mean_squared_error: 0.1014\n",
      "Epoch 106/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0108 - root_mean_squared_error: 0.1038 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 107/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1004\n",
      "Epoch 108/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0106 - root_mean_squared_error: 0.1032 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0997\n",
      "Epoch 109/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1032 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0996\n",
      "Epoch 110/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 111/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - root_mean_squared_error: 0.1035 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
      "Epoch 112/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0106 - root_mean_squared_error: 0.1027 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0992\n",
      "Epoch 113/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0106 - root_mean_squared_error: 0.1030 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0991\n",
      "Epoch 114/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - root_mean_squared_error: 0.1032 - val_loss: 0.0101 - val_root_mean_squared_error: 0.1003\n",
      "Epoch 115/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0105 - root_mean_squared_error: 0.1025 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 116/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0105 - root_mean_squared_error: 0.1024 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1000\n",
      "Epoch 117/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0106 - root_mean_squared_error: 0.1027 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0982\n",
      "Epoch 118/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0104 - root_mean_squared_error: 0.1018 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0993\n",
      "Epoch 119/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0103 - root_mean_squared_error: 0.1016 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0983\n",
      "Epoch 120/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0103 - root_mean_squared_error: 0.1017 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0979\n",
      "Epoch 121/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0103 - root_mean_squared_error: 0.1013 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 122/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0104 - root_mean_squared_error: 0.1019 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0976\n",
      "Epoch 123/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0104 - root_mean_squared_error: 0.1019 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0985\n",
      "Epoch 124/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - root_mean_squared_error: 0.1013 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 125/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0102 - root_mean_squared_error: 0.1011 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0989\n",
      "Epoch 126/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - root_mean_squared_error: 0.1007 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 127/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 128/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0102 - root_mean_squared_error: 0.1010 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
      "Epoch 129/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - root_mean_squared_error: 0.1004 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 130/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0101 - root_mean_squared_error: 0.1005 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0968\n",
      "Epoch 131/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0101 - root_mean_squared_error: 0.1003 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
      "Epoch 132/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0972\n",
      "Epoch 133/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0102 - root_mean_squared_error: 0.1011 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 134/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0103 - root_mean_squared_error: 0.1015 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0974\n",
      "Epoch 135/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - root_mean_squared_error: 0.1001 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 136/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - root_mean_squared_error: 0.0996 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0964\n",
      "Epoch 137/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - root_mean_squared_error: 0.1002 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
      "Epoch 138/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0099 - root_mean_squared_error: 0.0995 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 139/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - root_mean_squared_error: 0.0998 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
      "Epoch 140/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - root_mean_squared_error: 0.1005 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
      "Epoch 141/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
      "Epoch 142/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0100 - root_mean_squared_error: 0.1000 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0954\n",
      "Epoch 143/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0100 - root_mean_squared_error: 0.1000 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0956\n",
      "Epoch 144/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - root_mean_squared_error: 0.0990 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 145/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - root_mean_squared_error: 0.0991 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
      "Epoch 146/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0098 - root_mean_squared_error: 0.0991 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 147/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0952\n",
      "Epoch 148/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0098 - root_mean_squared_error: 0.0989 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0953\n",
      "Epoch 149/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0098 - root_mean_squared_error: 0.0988 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 150/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0949\n",
      "Epoch 151/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0945\n",
      "Epoch 152/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0097 - root_mean_squared_error: 0.0985 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0948\n",
      "Epoch 153/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0091 - val_root_mean_squared_error: 0.0955\n",
      "Epoch 154/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0099 - root_mean_squared_error: 0.0994 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 155/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097 - root_mean_squared_error: 0.0983 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 156/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 157/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 158/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0097 - root_mean_squared_error: 0.0986 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939\n",
      "Epoch 159/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0096 - root_mean_squared_error: 0.0977 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0941\n",
      "Epoch 160/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - root_mean_squared_error: 0.0980 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0940\n",
      "Epoch 161/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0095 - root_mean_squared_error: 0.0977 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 162/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - root_mean_squared_error: 0.0977 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0937\n",
      "Epoch 163/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 164/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0096 - root_mean_squared_error: 0.0979 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 165/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - root_mean_squared_error: 0.0977 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933\n",
      "Epoch 166/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0098 - root_mean_squared_error: 0.0992 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
      "Epoch 167/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0097 - root_mean_squared_error: 0.0984 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 168/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0096 - root_mean_squared_error: 0.0978 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 169/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0938\n",
      "Epoch 170/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 171/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0094 - root_mean_squared_error: 0.0971 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929\n",
      "Epoch 172/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 173/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 174/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - root_mean_squared_error: 0.0969 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 175/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 176/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930\n",
      "Epoch 177/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - root_mean_squared_error: 0.0972 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0925\n",
      "Epoch 178/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - root_mean_squared_error: 0.0974 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 179/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 180/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
      "Epoch 181/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 182/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - root_mean_squared_error: 0.0964 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 183/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0094 - root_mean_squared_error: 0.0972 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0921\n",
      "Epoch 184/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0095 - root_mean_squared_error: 0.0972 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0927\n",
      "Epoch 185/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 186/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0095 - root_mean_squared_error: 0.0973 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0919\n",
      "Epoch 187/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0095 - root_mean_squared_error: 0.0977 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 188/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0092 - root_mean_squared_error: 0.0959 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 189/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
      "Epoch 190/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - root_mean_squared_error: 0.0962 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 191/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - root_mean_squared_error: 0.0960 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 192/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0900\n",
      "Epoch 193/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - root_mean_squared_error: 0.0962 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
      "Epoch 194/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0901\n",
      "Epoch 195/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0957 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 196/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - root_mean_squared_error: 0.0967 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 197/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - root_mean_squared_error: 0.0963 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0893\n",
      "Epoch 198/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
      "Epoch 199/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - root_mean_squared_error: 0.0953 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 200/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - root_mean_squared_error: 0.0949 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0894\n",
      "Epoch 201/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 202/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - root_mean_squared_error: 0.0946 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 203/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0090 - root_mean_squared_error: 0.0950 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0885\n",
      "Epoch 204/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - root_mean_squared_error: 0.0948 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 205/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0944 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0892\n",
      "Epoch 206/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0090 - root_mean_squared_error: 0.0947 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0883\n",
      "Epoch 207/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0089 - root_mean_squared_error: 0.0945 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0888\n",
      "Epoch 208/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - root_mean_squared_error: 0.0942 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0882\n",
      "Epoch 209/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
      "Epoch 210/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0088 - root_mean_squared_error: 0.0939 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 211/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0091 - root_mean_squared_error: 0.0955 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 212/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 213/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - root_mean_squared_error: 0.0936 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0873\n",
      "Epoch 214/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - root_mean_squared_error: 0.0940 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 215/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0089 - root_mean_squared_error: 0.0943 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0874\n",
      "Epoch 216/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - root_mean_squared_error: 0.0951 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 217/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0092 - root_mean_squared_error: 0.0960 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0891\n",
      "Epoch 218/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0090 - root_mean_squared_error: 0.0947 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0869\n",
      "Epoch 219/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - root_mean_squared_error: 0.0941 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 220/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - root_mean_squared_error: 0.0940 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 221/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0931 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 222/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - root_mean_squared_error: 0.0932 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0867\n",
      "Epoch 223/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0935 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0864\n",
      "Epoch 224/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - root_mean_squared_error: 0.0934 - val_loss: 0.0078 - val_root_mean_squared_error: 0.0881\n",
      "Epoch 225/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - root_mean_squared_error: 0.0930 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 226/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087 - root_mean_squared_error: 0.0932 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0866\n",
      "Epoch 227/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0088 - root_mean_squared_error: 0.0936 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 228/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0087 - root_mean_squared_error: 0.0932 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 229/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - root_mean_squared_error: 0.0927 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 230/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - root_mean_squared_error: 0.0927 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
      "Epoch 231/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - root_mean_squared_error: 0.0928 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0862\n",
      "Epoch 232/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0075 - val_root_mean_squared_error: 0.0868\n",
      "Epoch 233/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - root_mean_squared_error: 0.0939 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 234/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092 - root_mean_squared_error: 0.0960 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0914\n",
      "Epoch 235/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0858\n",
      "Epoch 236/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0932 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 237/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - root_mean_squared_error: 0.0921 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 238/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0086 - root_mean_squared_error: 0.0926 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 239/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - root_mean_squared_error: 0.0921 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0852\n",
      "Epoch 240/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0856\n",
      "Epoch 241/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - root_mean_squared_error: 0.0925 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
      "Epoch 242/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0085 - root_mean_squared_error: 0.0922 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 243/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 244/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 245/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0846\n",
      "Epoch 246/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 247/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 248/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 249/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0083 - root_mean_squared_error: 0.0913 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 250/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085 - root_mean_squared_error: 0.0919 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
      "Epoch 251/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0086 - root_mean_squared_error: 0.0927 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 252/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0085 - root_mean_squared_error: 0.0923 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0848\n",
      "Epoch 253/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0083 - root_mean_squared_error: 0.0913 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0847\n",
      "Epoch 254/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 255/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 256/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - root_mean_squared_error: 0.0914 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 257/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0851\n",
      "Epoch 258/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 259/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 260/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - root_mean_squared_error: 0.0913 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 261/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 262/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0912 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0840\n",
      "Epoch 263/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0843\n",
      "Epoch 264/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 265/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n",
      "Epoch 266/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 267/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 268/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0082 - root_mean_squared_error: 0.0906 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 269/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 270/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 271/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0082 - root_mean_squared_error: 0.0904 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 272/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0855\n",
      "Epoch 273/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 274/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - root_mean_squared_error: 0.0909 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0837\n",
      "Epoch 275/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0082 - root_mean_squared_error: 0.0903 - val_loss: 0.0072 - val_root_mean_squared_error: 0.0850\n",
      "Epoch 276/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0908 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 277/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0087 - root_mean_squared_error: 0.0931 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0871\n",
      "Epoch 278/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 279/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0082 - root_mean_squared_error: 0.0906 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 280/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0081 - root_mean_squared_error: 0.0900 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0845\n",
      "Epoch 281/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0081 - root_mean_squared_error: 0.0902 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 282/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0839\n",
      "Epoch 283/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 284/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0834\n",
      "Epoch 285/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080 - root_mean_squared_error: 0.0895 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0836\n",
      "Epoch 286/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - root_mean_squared_error: 0.0901 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0831\n",
      "Epoch 287/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 288/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 289/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 290/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0080 - root_mean_squared_error: 0.0896 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0861\n",
      "Epoch 291/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - root_mean_squared_error: 0.0890 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 292/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
      "Epoch 293/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0829\n",
      "Epoch 294/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0080 - root_mean_squared_error: 0.0893 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0830\n",
      "Epoch 295/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0080 - root_mean_squared_error: 0.0892 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0833\n",
      "Epoch 296/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0080 - root_mean_squared_error: 0.0897 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 297/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0081 - root_mean_squared_error: 0.0898 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
      "Epoch 298/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0082 - root_mean_squared_error: 0.0906 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0828\n",
      "Epoch 299/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - val_loss: 0.0069 - val_root_mean_squared_error: 0.0832\n",
      "Epoch 300/300\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0079 - root_mean_squared_error: 0.0891 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ae932ed4e0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(x=X_train,y=y_train,epochs=300,validation_data=(X_test,y_test))\n",
    "model.fit(x=X_train,y=y_train,epochs=300,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2c8589a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4586358666419983,\n",
       "  0.1738862693309784,\n",
       "  0.11385354399681091,\n",
       "  0.10532619804143906,\n",
       "  0.09137566387653351,\n",
       "  0.08162561804056168,\n",
       "  0.07463087141513824,\n",
       "  0.06876374036073685,\n",
       "  0.06430152803659439,\n",
       "  0.061074044555425644,\n",
       "  0.0579911507666111,\n",
       "  0.055530693382024765,\n",
       "  0.053382351994514465,\n",
       "  0.051531292498111725,\n",
       "  0.04985334351658821,\n",
       "  0.048054732382297516,\n",
       "  0.046452879905700684,\n",
       "  0.04503391310572624,\n",
       "  0.043739497661590576,\n",
       "  0.042299870401620865,\n",
       "  0.04112263768911362,\n",
       "  0.03994916006922722,\n",
       "  0.03888475522398949,\n",
       "  0.03780277445912361,\n",
       "  0.03669138625264168,\n",
       "  0.03557597100734711,\n",
       "  0.03471732139587402,\n",
       "  0.03373534604907036,\n",
       "  0.03282507136464119,\n",
       "  0.03198302164673805,\n",
       "  0.03136996179819107,\n",
       "  0.030224662274122238,\n",
       "  0.029636552557349205,\n",
       "  0.028971830382943153,\n",
       "  0.028208930045366287,\n",
       "  0.027379492297768593,\n",
       "  0.02683948166668415,\n",
       "  0.026084408164024353,\n",
       "  0.025418199598789215,\n",
       "  0.025042401626706123,\n",
       "  0.024712050333619118,\n",
       "  0.023535341024398804,\n",
       "  0.023114001378417015,\n",
       "  0.022360552102327347,\n",
       "  0.021872449666261673,\n",
       "  0.02121184580028057,\n",
       "  0.020761946216225624,\n",
       "  0.020317088812589645,\n",
       "  0.02014811895787716,\n",
       "  0.019505411386489868,\n",
       "  0.01912958174943924,\n",
       "  0.018658243119716644,\n",
       "  0.018305344507098198,\n",
       "  0.01790338195860386,\n",
       "  0.017719794064760208,\n",
       "  0.017228227108716965,\n",
       "  0.016952602192759514,\n",
       "  0.016609210520982742,\n",
       "  0.016316400840878487,\n",
       "  0.01602262817323208,\n",
       "  0.01580437645316124,\n",
       "  0.015506336465477943,\n",
       "  0.01524414774030447,\n",
       "  0.01510861236602068,\n",
       "  0.014834589324891567,\n",
       "  0.014573104679584503,\n",
       "  0.014445243403315544,\n",
       "  0.014204907231032848,\n",
       "  0.014058979228138924,\n",
       "  0.013858799822628498,\n",
       "  0.013657600618898869,\n",
       "  0.013506031595170498,\n",
       "  0.013367051258683205,\n",
       "  0.013229061849415302,\n",
       "  0.01312694326043129,\n",
       "  0.012990293093025684,\n",
       "  0.012810288928449154,\n",
       "  0.012703977525234222,\n",
       "  0.012638971209526062,\n",
       "  0.012472064234316349,\n",
       "  0.01238747127354145,\n",
       "  0.01239234209060669,\n",
       "  0.012459653429687023,\n",
       "  0.01199739146977663,\n",
       "  0.011971400119364262,\n",
       "  0.012018412351608276,\n",
       "  0.011754348874092102,\n",
       "  0.011714286170899868,\n",
       "  0.01165618747472763,\n",
       "  0.011590327136218548,\n",
       "  0.011667315848171711,\n",
       "  0.01158130168914795,\n",
       "  0.011360534466803074,\n",
       "  0.011353288777172565,\n",
       "  0.011231456883251667,\n",
       "  0.01125261839479208,\n",
       "  0.011126967146992683,\n",
       "  0.011168803088366985,\n",
       "  0.011018151417374611,\n",
       "  0.011018361896276474,\n",
       "  0.01099188718944788,\n",
       "  0.010878349654376507,\n",
       "  0.011071688495576382,\n",
       "  0.011144637130200863,\n",
       "  0.010848534293472767,\n",
       "  0.010781299322843552,\n",
       "  0.010919750668108463,\n",
       "  0.010645129717886448,\n",
       "  0.01065211370587349,\n",
       "  0.01071265060454607,\n",
       "  0.010714230127632618,\n",
       "  0.01055555883795023,\n",
       "  0.010605063289403915,\n",
       "  0.010647560469806194,\n",
       "  0.010501760058104992,\n",
       "  0.010479092597961426,\n",
       "  0.010553378611803055,\n",
       "  0.010364605113863945,\n",
       "  0.010328722186386585,\n",
       "  0.010334046557545662,\n",
       "  0.010262074880301952,\n",
       "  0.010379982180893421,\n",
       "  0.010384474880993366,\n",
       "  0.010267936624586582,\n",
       "  0.010218889452517033,\n",
       "  0.010138998739421368,\n",
       "  0.010201561264693737,\n",
       "  0.01020047813653946,\n",
       "  0.010079720988869667,\n",
       "  0.010093357414007187,\n",
       "  0.010060840286314487,\n",
       "  0.010125509463250637,\n",
       "  0.010229798965156078,\n",
       "  0.010306532494723797,\n",
       "  0.010012800805270672,\n",
       "  0.009923531673848629,\n",
       "  0.01003965176641941,\n",
       "  0.009898564778268337,\n",
       "  0.009965000674128532,\n",
       "  0.0101036811247468,\n",
       "  0.010116671212017536,\n",
       "  0.009996035136282444,\n",
       "  0.009993068873882294,\n",
       "  0.009799019433557987,\n",
       "  0.009825334884226322,\n",
       "  0.00982228759676218,\n",
       "  0.009723355062305927,\n",
       "  0.009776612743735313,\n",
       "  0.009751654230058193,\n",
       "  0.009695319458842278,\n",
       "  0.009698936715722084,\n",
       "  0.009695864282548428,\n",
       "  0.009731425903737545,\n",
       "  0.009881475009024143,\n",
       "  0.00965901929885149,\n",
       "  0.009621202014386654,\n",
       "  0.009724526666104794,\n",
       "  0.009716230444610119,\n",
       "  0.009554080665111542,\n",
       "  0.009603523649275303,\n",
       "  0.009549843147397041,\n",
       "  0.00954021979123354,\n",
       "  0.0096483388915658,\n",
       "  0.009575764648616314,\n",
       "  0.009541437961161137,\n",
       "  0.009837835095822811,\n",
       "  0.009684745222330093,\n",
       "  0.009571119211614132,\n",
       "  0.00945768691599369,\n",
       "  0.009401561692357063,\n",
       "  0.009424268268048763,\n",
       "  0.009527463465929031,\n",
       "  0.009393294341862202,\n",
       "  0.00939003936946392,\n",
       "  0.00940636731684208,\n",
       "  0.009415525011718273,\n",
       "  0.009456963278353214,\n",
       "  0.009490340016782284,\n",
       "  0.009327732026576996,\n",
       "  0.009475868195295334,\n",
       "  0.009323213249444962,\n",
       "  0.009287654422223568,\n",
       "  0.009443706832826138,\n",
       "  0.009457132779061794,\n",
       "  0.00932270660996437,\n",
       "  0.009465675801038742,\n",
       "  0.00954282097518444,\n",
       "  0.009198798798024654,\n",
       "  0.00927288644015789,\n",
       "  0.009258096106350422,\n",
       "  0.009222079999744892,\n",
       "  0.009276065044105053,\n",
       "  0.009249670431017876,\n",
       "  0.009129572659730911,\n",
       "  0.009156646206974983,\n",
       "  0.009342481382191181,\n",
       "  0.00926893763244152,\n",
       "  0.009402847848832607,\n",
       "  0.00909093301743269,\n",
       "  0.009012776426970959,\n",
       "  0.009120073169469833,\n",
       "  0.008953290991485119,\n",
       "  0.00902189128100872,\n",
       "  0.00898860301822424,\n",
       "  0.008904444053769112,\n",
       "  0.00896068662405014,\n",
       "  0.008932190015912056,\n",
       "  0.008868210017681122,\n",
       "  0.00888906791806221,\n",
       "  0.008818242698907852,\n",
       "  0.00911830086261034,\n",
       "  0.008788321167230606,\n",
       "  0.008766823448240757,\n",
       "  0.008838552981615067,\n",
       "  0.008885785937309265,\n",
       "  0.009042875841259956,\n",
       "  0.009219320490956306,\n",
       "  0.00896456278860569,\n",
       "  0.008845682255923748,\n",
       "  0.008843653835356236,\n",
       "  0.008671704679727554,\n",
       "  0.008684341795742512,\n",
       "  0.00874246470630169,\n",
       "  0.00873199850320816,\n",
       "  0.00865089800208807,\n",
       "  0.00868734810501337,\n",
       "  0.008759675547480583,\n",
       "  0.008678680285811424,\n",
       "  0.008598240092396736,\n",
       "  0.008597798645496368,\n",
       "  0.008607616648077965,\n",
       "  0.008628581650555134,\n",
       "  0.008822993375360966,\n",
       "  0.009220074862241745,\n",
       "  0.009336361661553383,\n",
       "  0.008679193444550037,\n",
       "  0.008479582145810127,\n",
       "  0.008571830578148365,\n",
       "  0.008483665063977242,\n",
       "  0.008466106839478016,\n",
       "  0.008553844876587391,\n",
       "  0.008503058925271034,\n",
       "  0.00840537529438734,\n",
       "  0.0084144975990057,\n",
       "  0.008442661724984646,\n",
       "  0.008446479216217995,\n",
       "  0.008405793458223343,\n",
       "  0.008376671001315117,\n",
       "  0.008336898870766163,\n",
       "  0.00845114141702652,\n",
       "  0.008592848666012287,\n",
       "  0.008522885851562023,\n",
       "  0.008343569934368134,\n",
       "  0.00826928112655878,\n",
       "  0.008404086343944073,\n",
       "  0.00835036113858223,\n",
       "  0.008369469083845615,\n",
       "  0.008279962465167046,\n",
       "  0.008253809064626694,\n",
       "  0.008327694609761238,\n",
       "  0.00831737369298935,\n",
       "  0.008320295251905918,\n",
       "  0.008290748111903667,\n",
       "  0.00829123705625534,\n",
       "  0.008246909826993942,\n",
       "  0.008248453959822655,\n",
       "  0.008116703480482101,\n",
       "  0.008204277604818344,\n",
       "  0.008299616165459156,\n",
       "  0.008140619844198227,\n",
       "  0.00818058755248785,\n",
       "  0.008397722616791725,\n",
       "  0.008263968862593174,\n",
       "  0.008265928365290165,\n",
       "  0.008158938959240913,\n",
       "  0.008243320509791374,\n",
       "  0.008667290210723877,\n",
       "  0.008397193625569344,\n",
       "  0.008208534680306911,\n",
       "  0.008098658174276352,\n",
       "  0.008132623508572578,\n",
       "  0.00804178323596716,\n",
       "  0.007982169277966022,\n",
       "  0.0080368397757411,\n",
       "  0.00800385419279337,\n",
       "  0.008109288290143013,\n",
       "  0.00804141629487276,\n",
       "  0.007982711307704449,\n",
       "  0.008038889616727829,\n",
       "  0.008028765209019184,\n",
       "  0.007920430973172188,\n",
       "  0.008271914906799793,\n",
       "  0.008038832806050777,\n",
       "  0.00797700509428978,\n",
       "  0.007951122708618641,\n",
       "  0.008038084954023361,\n",
       "  0.008056748658418655,\n",
       "  0.00820019468665123,\n",
       "  0.007934574037790298,\n",
       "  0.007942636497318745],\n",
       " 'root_mean_squared_error': [0.6772266030311584,\n",
       "  0.41699671745300293,\n",
       "  0.33742189407348633,\n",
       "  0.32453998923301697,\n",
       "  0.3022840917110443,\n",
       "  0.2857019603252411,\n",
       "  0.27318650484085083,\n",
       "  0.262228399515152,\n",
       "  0.25357747077941895,\n",
       "  0.24713163077831268,\n",
       "  0.24081352353096008,\n",
       "  0.23564951121807098,\n",
       "  0.23104621469974518,\n",
       "  0.22700504958629608,\n",
       "  0.22327862679958344,\n",
       "  0.21921390295028687,\n",
       "  0.21552930772304535,\n",
       "  0.2122119516134262,\n",
       "  0.2091398984193802,\n",
       "  0.2056693285703659,\n",
       "  0.20278717577457428,\n",
       "  0.19987286627292633,\n",
       "  0.19719217717647552,\n",
       "  0.19442935287952423,\n",
       "  0.19154995679855347,\n",
       "  0.18861593306064606,\n",
       "  0.18632584810256958,\n",
       "  0.18367184698581696,\n",
       "  0.18117690086364746,\n",
       "  0.17883796989917755,\n",
       "  0.17711567878723145,\n",
       "  0.17385241389274597,\n",
       "  0.17215269804000854,\n",
       "  0.17021113634109497,\n",
       "  0.16795514523983002,\n",
       "  0.1654675006866455,\n",
       "  0.16382759809494019,\n",
       "  0.16150668263435364,\n",
       "  0.1594308614730835,\n",
       "  0.1582479178905487,\n",
       "  0.1572006642818451,\n",
       "  0.153412327170372,\n",
       "  0.15203289687633514,\n",
       "  0.1495344489812851,\n",
       "  0.14789336919784546,\n",
       "  0.14564287662506104,\n",
       "  0.14409005641937256,\n",
       "  0.14253802597522736,\n",
       "  0.1419440656900406,\n",
       "  0.1396617740392685,\n",
       "  0.13830973207950592,\n",
       "  0.13659517467021942,\n",
       "  0.1352972388267517,\n",
       "  0.13380351662635803,\n",
       "  0.1331157237291336,\n",
       "  0.1312563419342041,\n",
       "  0.13020215928554535,\n",
       "  0.128876730799675,\n",
       "  0.1277356743812561,\n",
       "  0.12658052146434784,\n",
       "  0.1257154643535614,\n",
       "  0.12452444434165955,\n",
       "  0.12346719205379486,\n",
       "  0.12291709333658218,\n",
       "  0.12179733067750931,\n",
       "  0.12071911245584488,\n",
       "  0.12018836289644241,\n",
       "  0.11918434500694275,\n",
       "  0.11857056617736816,\n",
       "  0.11772340536117554,\n",
       "  0.11686573922634125,\n",
       "  0.11621545255184174,\n",
       "  0.11561596393585205,\n",
       "  0.11501765996217728,\n",
       "  0.11457287520170212,\n",
       "  0.11397496610879898,\n",
       "  0.11318254470825195,\n",
       "  0.11271192133426666,\n",
       "  0.11242318153381348,\n",
       "  0.11167839914560318,\n",
       "  0.11129901558160782,\n",
       "  0.11132089793682098,\n",
       "  0.11162281781435013,\n",
       "  0.10953260213136673,\n",
       "  0.10941389203071594,\n",
       "  0.10962852090597153,\n",
       "  0.10841747373342514,\n",
       "  0.10823255777359009,\n",
       "  0.10796382278203964,\n",
       "  0.10765837877988815,\n",
       "  0.10801535099744797,\n",
       "  0.10761645436286926,\n",
       "  0.10658580809831619,\n",
       "  0.10655181109905243,\n",
       "  0.1059785708785057,\n",
       "  0.10607835650444031,\n",
       "  0.10548444092273712,\n",
       "  0.10568255931138992,\n",
       "  0.1049673855304718,\n",
       "  0.10496838390827179,\n",
       "  0.10484220087528229,\n",
       "  0.10429932922124863,\n",
       "  0.10522209107875824,\n",
       "  0.10556816309690475,\n",
       "  0.10415630042552948,\n",
       "  0.10383303463459015,\n",
       "  0.10449761152267456,\n",
       "  0.10317523777484894,\n",
       "  0.10320907831192017,\n",
       "  0.10350193828344345,\n",
       "  0.1035095676779747,\n",
       "  0.10274025052785873,\n",
       "  0.10298088937997818,\n",
       "  0.10318701714277267,\n",
       "  0.10247809439897537,\n",
       "  0.10236743837594986,\n",
       "  0.10272964090108871,\n",
       "  0.10180670768022537,\n",
       "  0.1016303226351738,\n",
       "  0.10165651142597198,\n",
       "  0.1013019010424614,\n",
       "  0.1018821969628334,\n",
       "  0.1019042432308197,\n",
       "  0.10133082419633865,\n",
       "  0.1010885238647461,\n",
       "  0.10069259256124496,\n",
       "  0.1010027751326561,\n",
       "  0.10099741816520691,\n",
       "  0.10039781033992767,\n",
       "  0.10046570003032684,\n",
       "  0.10030373930931091,\n",
       "  0.10062558948993683,\n",
       "  0.10114246606826782,\n",
       "  0.1015210971236229,\n",
       "  0.1000639870762825,\n",
       "  0.09961692243814468,\n",
       "  0.10019806027412415,\n",
       "  0.09949152916669846,\n",
       "  0.09982485324144363,\n",
       "  0.10051707178354263,\n",
       "  0.10058166086673737,\n",
       "  0.0999801754951477,\n",
       "  0.09996534138917923,\n",
       "  0.09898999333381653,\n",
       "  0.09912282973527908,\n",
       "  0.09910745173692703,\n",
       "  0.09860707074403763,\n",
       "  0.09887675195932388,\n",
       "  0.09875046461820602,\n",
       "  0.09846481680870056,\n",
       "  0.09848318248987198,\n",
       "  0.09846758097410202,\n",
       "  0.09864798933267593,\n",
       "  0.09940560907125473,\n",
       "  0.09828031063079834,\n",
       "  0.09808772802352905,\n",
       "  0.09861301630735397,\n",
       "  0.09857094287872314,\n",
       "  0.09774497896432877,\n",
       "  0.09799756854772568,\n",
       "  0.09772329777479172,\n",
       "  0.09767404943704605,\n",
       "  0.09822595864534378,\n",
       "  0.0978558361530304,\n",
       "  0.09768028557300568,\n",
       "  0.09918586164712906,\n",
       "  0.09841110557317734,\n",
       "  0.0978320986032486,\n",
       "  0.09725064039230347,\n",
       "  0.09696164727210999,\n",
       "  0.09707867354154587,\n",
       "  0.09760872274637222,\n",
       "  0.09691900759935379,\n",
       "  0.09690221399068832,\n",
       "  0.09698642790317535,\n",
       "  0.09703362733125687,\n",
       "  0.0972469225525856,\n",
       "  0.09741837531328201,\n",
       "  0.09658018499612808,\n",
       "  0.09734407067298889,\n",
       "  0.09655679017305374,\n",
       "  0.09637247771024704,\n",
       "  0.09717873483896255,\n",
       "  0.09724779427051544,\n",
       "  0.09655416756868362,\n",
       "  0.09729170799255371,\n",
       "  0.09768736362457275,\n",
       "  0.09591037034988403,\n",
       "  0.09629582613706589,\n",
       "  0.096219003200531,\n",
       "  0.09603165835142136,\n",
       "  0.09631232917308807,\n",
       "  0.09617520868778229,\n",
       "  0.09554879367351532,\n",
       "  0.09569036960601807,\n",
       "  0.09665650874376297,\n",
       "  0.09627532213926315,\n",
       "  0.09696828573942184,\n",
       "  0.09534638375043869,\n",
       "  0.09493564069271088,\n",
       "  0.09549907594919205,\n",
       "  0.09462182968854904,\n",
       "  0.09498363733291626,\n",
       "  0.09480824321508408,\n",
       "  0.09436336159706116,\n",
       "  0.09466090053319931,\n",
       "  0.0945102646946907,\n",
       "  0.09417117387056351,\n",
       "  0.09428185224533081,\n",
       "  0.0939055010676384,\n",
       "  0.09548979252576828,\n",
       "  0.09374604374170303,\n",
       "  0.0936313197016716,\n",
       "  0.09401357918977737,\n",
       "  0.0942644476890564,\n",
       "  0.09509404003620148,\n",
       "  0.09601729363203049,\n",
       "  0.09468137472867966,\n",
       "  0.09405148774385452,\n",
       "  0.09404070675373077,\n",
       "  0.09312199056148529,\n",
       "  0.09318981319665909,\n",
       "  0.09350115060806274,\n",
       "  0.09344515949487686,\n",
       "  0.09301020205020905,\n",
       "  0.09320594370365143,\n",
       "  0.09359313547611237,\n",
       "  0.09315943717956543,\n",
       "  0.0927266925573349,\n",
       "  0.09272431582212448,\n",
       "  0.09277724474668503,\n",
       "  0.09289015829563141,\n",
       "  0.09393078833818436,\n",
       "  0.09602122008800507,\n",
       "  0.09662485122680664,\n",
       "  0.0931621864438057,\n",
       "  0.09208464622497559,\n",
       "  0.09258417785167694,\n",
       "  0.09210681170225143,\n",
       "  0.0920114517211914,\n",
       "  0.09248699992895126,\n",
       "  0.09221202880144119,\n",
       "  0.09168083220720291,\n",
       "  0.09173057228326797,\n",
       "  0.09188395738601685,\n",
       "  0.09190472960472107,\n",
       "  0.09168311208486557,\n",
       "  0.0915241539478302,\n",
       "  0.09130661934614182,\n",
       "  0.091930091381073,\n",
       "  0.0926976203918457,\n",
       "  0.09231947362422943,\n",
       "  0.09134314209222794,\n",
       "  0.0909355878829956,\n",
       "  0.09167380630970001,\n",
       "  0.09138031303882599,\n",
       "  0.09148479998111725,\n",
       "  0.09099429845809937,\n",
       "  0.09085047990083694,\n",
       "  0.09125620126724243,\n",
       "  0.09119963645935059,\n",
       "  0.09121565520763397,\n",
       "  0.0910535454750061,\n",
       "  0.091056227684021,\n",
       "  0.09081249684095383,\n",
       "  0.09082099795341492,\n",
       "  0.0900927484035492,\n",
       "  0.09057746827602386,\n",
       "  0.0911022275686264,\n",
       "  0.09022538363933563,\n",
       "  0.0904465988278389,\n",
       "  0.09163908660411835,\n",
       "  0.09090637415647507,\n",
       "  0.09091714769601822,\n",
       "  0.09032684564590454,\n",
       "  0.09079273045063019,\n",
       "  0.09309828281402588,\n",
       "  0.09163620322942734,\n",
       "  0.09060096740722656,\n",
       "  0.08999254554510117,\n",
       "  0.09018106013536453,\n",
       "  0.08967599272727966,\n",
       "  0.08934298902750015,\n",
       "  0.08964842557907104,\n",
       "  0.08946426212787628,\n",
       "  0.09005158394575119,\n",
       "  0.08967394381761551,\n",
       "  0.0893460214138031,\n",
       "  0.08965985476970673,\n",
       "  0.08960337936878204,\n",
       "  0.08899680525064468,\n",
       "  0.09095007181167603,\n",
       "  0.08965954184532166,\n",
       "  0.08931407332420349,\n",
       "  0.08916907012462616,\n",
       "  0.08965536952018738,\n",
       "  0.08975939452648163,\n",
       "  0.09055492281913757,\n",
       "  0.08907622843980789,\n",
       "  0.08912146836519241],\n",
       " 'val_loss': [0.283620148897171,\n",
       "  0.12810826301574707,\n",
       "  0.10547176748514175,\n",
       "  0.09269636124372482,\n",
       "  0.08188627660274506,\n",
       "  0.07581543177366257,\n",
       "  0.06885126233100891,\n",
       "  0.06233348324894905,\n",
       "  0.05787302926182747,\n",
       "  0.05522582307457924,\n",
       "  0.05223097279667854,\n",
       "  0.050188012421131134,\n",
       "  0.047921620309352875,\n",
       "  0.04658694937825203,\n",
       "  0.04434390366077423,\n",
       "  0.04327581822872162,\n",
       "  0.041829176247119904,\n",
       "  0.040633801370859146,\n",
       "  0.039323385804891586,\n",
       "  0.03811890259385109,\n",
       "  0.036847129464149475,\n",
       "  0.0360020212829113,\n",
       "  0.03503371775150299,\n",
       "  0.03377927467226982,\n",
       "  0.03310278803110123,\n",
       "  0.032200850546360016,\n",
       "  0.031488075852394104,\n",
       "  0.030377456918358803,\n",
       "  0.029677102342247963,\n",
       "  0.028853431344032288,\n",
       "  0.028405437245965004,\n",
       "  0.027335064485669136,\n",
       "  0.026630764827132225,\n",
       "  0.026077061891555786,\n",
       "  0.025553032755851746,\n",
       "  0.024699673056602478,\n",
       "  0.024018967524170876,\n",
       "  0.023608922958374023,\n",
       "  0.02301100641489029,\n",
       "  0.02240060642361641,\n",
       "  0.022190436720848083,\n",
       "  0.021285276859998703,\n",
       "  0.02077551931142807,\n",
       "  0.02047833241522312,\n",
       "  0.019857291132211685,\n",
       "  0.01945192739367485,\n",
       "  0.018995117396116257,\n",
       "  0.018532676622271538,\n",
       "  0.018189238384366035,\n",
       "  0.017760029062628746,\n",
       "  0.0173249039798975,\n",
       "  0.016914911568164825,\n",
       "  0.0165691040456295,\n",
       "  0.01618284545838833,\n",
       "  0.015970494598150253,\n",
       "  0.015622895210981369,\n",
       "  0.015215396881103516,\n",
       "  0.01494625210762024,\n",
       "  0.014649072661995888,\n",
       "  0.014452594332396984,\n",
       "  0.014179090969264507,\n",
       "  0.013975580222904682,\n",
       "  0.013770041987299919,\n",
       "  0.01353393029421568,\n",
       "  0.013361454010009766,\n",
       "  0.013116804882884026,\n",
       "  0.012934105470776558,\n",
       "  0.012755520641803741,\n",
       "  0.012696264311671257,\n",
       "  0.012479288503527641,\n",
       "  0.012386317364871502,\n",
       "  0.012278321199119091,\n",
       "  0.012077719904482365,\n",
       "  0.011974728666245937,\n",
       "  0.01180071011185646,\n",
       "  0.011639258824288845,\n",
       "  0.01169043779373169,\n",
       "  0.011528923176229,\n",
       "  0.011456114239990711,\n",
       "  0.011333398520946503,\n",
       "  0.011259758844971657,\n",
       "  0.011216526851058006,\n",
       "  0.011120198294520378,\n",
       "  0.011360250413417816,\n",
       "  0.010961225256323814,\n",
       "  0.01088709756731987,\n",
       "  0.010935667902231216,\n",
       "  0.010806520469486713,\n",
       "  0.010684949345886707,\n",
       "  0.010678603313863277,\n",
       "  0.010590920224785805,\n",
       "  0.010647937655448914,\n",
       "  0.010475313290953636,\n",
       "  0.010558689013123512,\n",
       "  0.010477559641003609,\n",
       "  0.010396813973784447,\n",
       "  0.0104005616158247,\n",
       "  0.010313267819583416,\n",
       "  0.010398875921964645,\n",
       "  0.010288090445101261,\n",
       "  0.010167715139687061,\n",
       "  0.010285277850925922,\n",
       "  0.010118464007973671,\n",
       "  0.010099139995872974,\n",
       "  0.010284271091222763,\n",
       "  0.009992554783821106,\n",
       "  0.010070912539958954,\n",
       "  0.009932238608598709,\n",
       "  0.009919687174260616,\n",
       "  0.009863298386335373,\n",
       "  0.009901965036988258,\n",
       "  0.009838011115789413,\n",
       "  0.00982617773115635,\n",
       "  0.010062809102237225,\n",
       "  0.00974204484373331,\n",
       "  0.010007685050368309,\n",
       "  0.009651844389736652,\n",
       "  0.009853262454271317,\n",
       "  0.009665559977293015,\n",
       "  0.00959346815943718,\n",
       "  0.009692550636827946,\n",
       "  0.009523121640086174,\n",
       "  0.009698967449367046,\n",
       "  0.009545045904815197,\n",
       "  0.009786277078092098,\n",
       "  0.009453492239117622,\n",
       "  0.009439980611205101,\n",
       "  0.009541812352836132,\n",
       "  0.009339442476630211,\n",
       "  0.009373409673571587,\n",
       "  0.009337040595710278,\n",
       "  0.009453955106437206,\n",
       "  0.009285811334848404,\n",
       "  0.009490451775491238,\n",
       "  0.009224297478795052,\n",
       "  0.009289531968533993,\n",
       "  0.009227080270648003,\n",
       "  0.00919848307967186,\n",
       "  0.009191461838781834,\n",
       "  0.009168270044028759,\n",
       "  0.009219235740602016,\n",
       "  0.009109742939472198,\n",
       "  0.009142964147031307,\n",
       "  0.009115386754274368,\n",
       "  0.009044347330927849,\n",
       "  0.009004463441669941,\n",
       "  0.009072072803974152,\n",
       "  0.009077457711100578,\n",
       "  0.008989868685603142,\n",
       "  0.009003483690321445,\n",
       "  0.008937173523008823,\n",
       "  0.008986650966107845,\n",
       "  0.009122171439230442,\n",
       "  0.008895891718566418,\n",
       "  0.0089553352445364,\n",
       "  0.008863928727805614,\n",
       "  0.008856549859046936,\n",
       "  0.008813787251710892,\n",
       "  0.008862889371812344,\n",
       "  0.008844208903610706,\n",
       "  0.008805128745734692,\n",
       "  0.008788342587649822,\n",
       "  0.008891770616173744,\n",
       "  0.008709707297384739,\n",
       "  0.008704165928065777,\n",
       "  0.008765396662056446,\n",
       "  0.008801320567727089,\n",
       "  0.008649332448840141,\n",
       "  0.008802085183560848,\n",
       "  0.008642551489174366,\n",
       "  0.008632159791886806,\n",
       "  0.008640321902930737,\n",
       "  0.008645188994705677,\n",
       "  0.008641553111374378,\n",
       "  0.008595160208642483,\n",
       "  0.008652407675981522,\n",
       "  0.008563275448977947,\n",
       "  0.008520519360899925,\n",
       "  0.008480291813611984,\n",
       "  0.008517015725374222,\n",
       "  0.008474467322230339,\n",
       "  0.008693794719874859,\n",
       "  0.008488784544169903,\n",
       "  0.008586781099438667,\n",
       "  0.008400984108448029,\n",
       "  0.008438420481979847,\n",
       "  0.008319694548845291,\n",
       "  0.008345887064933777,\n",
       "  0.00831807591021061,\n",
       "  0.008227257989346981,\n",
       "  0.008166045881807804,\n",
       "  0.008108194917440414,\n",
       "  0.008274469524621964,\n",
       "  0.008124814368784428,\n",
       "  0.008175463415682316,\n",
       "  0.008010074496269226,\n",
       "  0.00798302236944437,\n",
       "  0.008258971385657787,\n",
       "  0.007940538227558136,\n",
       "  0.00799358356744051,\n",
       "  0.00794193334877491,\n",
       "  0.007930350489914417,\n",
       "  0.00783666130155325,\n",
       "  0.0079019321128726,\n",
       "  0.00796307623386383,\n",
       "  0.007796145975589752,\n",
       "  0.007882964797317982,\n",
       "  0.0077779958955943584,\n",
       "  0.007742508314549923,\n",
       "  0.007733004633337259,\n",
       "  0.007725079543888569,\n",
       "  0.007921457290649414,\n",
       "  0.0076293423771858215,\n",
       "  0.007638279348611832,\n",
       "  0.007630505133420229,\n",
       "  0.007556353695690632,\n",
       "  0.007940638810396194,\n",
       "  0.007545436266809702,\n",
       "  0.007524408400058746,\n",
       "  0.007601738907396793,\n",
       "  0.007582100573927164,\n",
       "  0.0075123910792171955,\n",
       "  0.0074613057076931,\n",
       "  0.007765912916511297,\n",
       "  0.007432400714606047,\n",
       "  0.007497415412217379,\n",
       "  0.007420399226248264,\n",
       "  0.007385286036878824,\n",
       "  0.007408719044178724,\n",
       "  0.007371685467660427,\n",
       "  0.007429294288158417,\n",
       "  0.007532323710620403,\n",
       "  0.007365515921264887,\n",
       "  0.00835409201681614,\n",
       "  0.0073554785922169685,\n",
       "  0.007396789267659187,\n",
       "  0.0072195460088551044,\n",
       "  0.007325483486056328,\n",
       "  0.007266183849424124,\n",
       "  0.0073289708234369755,\n",
       "  0.007387456949800253,\n",
       "  0.0072249057702720165,\n",
       "  0.0072257849387824535,\n",
       "  0.0072387936525046825,\n",
       "  0.007154190447181463,\n",
       "  0.007234324235469103,\n",
       "  0.007103086449205875,\n",
       "  0.007112675812095404,\n",
       "  0.007137936074286699,\n",
       "  0.007076704408973455,\n",
       "  0.007141136098653078,\n",
       "  0.007191459648311138,\n",
       "  0.00717324111610651,\n",
       "  0.007118143606930971,\n",
       "  0.0070510366931557655,\n",
       "  0.007098571863025427,\n",
       "  0.007234594784677029,\n",
       "  0.007040460593998432,\n",
       "  0.007062044460326433,\n",
       "  0.007231705356389284,\n",
       "  0.007134042680263519,\n",
       "  0.007048171944916248,\n",
       "  0.007106104865670204,\n",
       "  0.007012702524662018,\n",
       "  0.00696959812194109,\n",
       "  0.006980909500271082,\n",
       "  0.0071265255101025105,\n",
       "  0.007135908585041761,\n",
       "  0.0070015969686210155,\n",
       "  0.007144811097532511,\n",
       "  0.006951532792299986,\n",
       "  0.007306819781661034,\n",
       "  0.006984321866184473,\n",
       "  0.007004417944699526,\n",
       "  0.007228014525026083,\n",
       "  0.0069473241455852985,\n",
       "  0.007594211958348751,\n",
       "  0.006926625035703182,\n",
       "  0.006950552575290203,\n",
       "  0.007138700690120459,\n",
       "  0.006918739527463913,\n",
       "  0.007041396573185921,\n",
       "  0.006882579531520605,\n",
       "  0.006960262078791857,\n",
       "  0.006986719556152821,\n",
       "  0.006908324547111988,\n",
       "  0.00686374306678772,\n",
       "  0.007115895859897137,\n",
       "  0.006916579324752092,\n",
       "  0.0074082305654883385,\n",
       "  0.006923232227563858,\n",
       "  0.007122208829969168,\n",
       "  0.0068787094205617905,\n",
       "  0.006896198261529207,\n",
       "  0.006936271209269762,\n",
       "  0.006926519330590963,\n",
       "  0.007604287005960941,\n",
       "  0.006850713863968849,\n",
       "  0.006924909073859453,\n",
       "  0.006964952684938908],\n",
       " 'val_root_mean_squared_error': [0.5325599908828735,\n",
       "  0.35792213678359985,\n",
       "  0.3247641623020172,\n",
       "  0.3044607639312744,\n",
       "  0.2861577868461609,\n",
       "  0.2753460109233856,\n",
       "  0.2623952329158783,\n",
       "  0.2496667504310608,\n",
       "  0.2405681312084198,\n",
       "  0.23500175774097443,\n",
       "  0.22854097187519073,\n",
       "  0.22402681410312653,\n",
       "  0.2189100682735443,\n",
       "  0.21584010124206543,\n",
       "  0.21057991683483124,\n",
       "  0.2080284059047699,\n",
       "  0.20452181994915009,\n",
       "  0.2015782743692398,\n",
       "  0.1983012557029724,\n",
       "  0.19524063169956207,\n",
       "  0.1919560581445694,\n",
       "  0.18974198400974274,\n",
       "  0.18717296421527863,\n",
       "  0.183791384100914,\n",
       "  0.18194171786308289,\n",
       "  0.17944595217704773,\n",
       "  0.1774487942457199,\n",
       "  0.17429129779338837,\n",
       "  0.17227043211460114,\n",
       "  0.16986297070980072,\n",
       "  0.1685391217470169,\n",
       "  0.16533319652080536,\n",
       "  0.1631893515586853,\n",
       "  0.16148394346237183,\n",
       "  0.15985316038131714,\n",
       "  0.15716129541397095,\n",
       "  0.15498054027557373,\n",
       "  0.15365195274353027,\n",
       "  0.15169379115104675,\n",
       "  0.14966832101345062,\n",
       "  0.1489645540714264,\n",
       "  0.14589475095272064,\n",
       "  0.1441371589899063,\n",
       "  0.1431025266647339,\n",
       "  0.1409159004688263,\n",
       "  0.1394701600074768,\n",
       "  0.13782277703285217,\n",
       "  0.1361347734928131,\n",
       "  0.13486748933792114,\n",
       "  0.13326676189899445,\n",
       "  0.13162410259246826,\n",
       "  0.13005733489990234,\n",
       "  0.12872102856636047,\n",
       "  0.1272118091583252,\n",
       "  0.12637442350387573,\n",
       "  0.12499158084392548,\n",
       "  0.12335070967674255,\n",
       "  0.1222548633813858,\n",
       "  0.12103335559368134,\n",
       "  0.12021894007921219,\n",
       "  0.11907599121332169,\n",
       "  0.11821835488080978,\n",
       "  0.11734582483768463,\n",
       "  0.1163354218006134,\n",
       "  0.11559175699949265,\n",
       "  0.11452861875295639,\n",
       "  0.11372821033000946,\n",
       "  0.11294034123420715,\n",
       "  0.11267770081758499,\n",
       "  0.11171073466539383,\n",
       "  0.11129382997751236,\n",
       "  0.11080758273601532,\n",
       "  0.10989867895841599,\n",
       "  0.10942910611629486,\n",
       "  0.10863107442855835,\n",
       "  0.10788539797067642,\n",
       "  0.1081223264336586,\n",
       "  0.10737282037734985,\n",
       "  0.10703323781490326,\n",
       "  0.10645843297243118,\n",
       "  0.10611201077699661,\n",
       "  0.10590810328722,\n",
       "  0.10545235127210617,\n",
       "  0.10658447444438934,\n",
       "  0.1046958714723587,\n",
       "  0.10434125363826752,\n",
       "  0.10457374155521393,\n",
       "  0.10395441204309464,\n",
       "  0.10336802899837494,\n",
       "  0.10333732515573502,\n",
       "  0.10291219502687454,\n",
       "  0.10318884253501892,\n",
       "  0.10234897583723068,\n",
       "  0.10275547951459885,\n",
       "  0.10235995054244995,\n",
       "  0.10196477174758911,\n",
       "  0.10198314487934113,\n",
       "  0.1015542596578598,\n",
       "  0.10197488218545914,\n",
       "  0.10143022239208221,\n",
       "  0.10083509236574173,\n",
       "  0.10141635686159134,\n",
       "  0.10059057921171188,\n",
       "  0.10049447417259216,\n",
       "  0.10141139477491379,\n",
       "  0.0999627634882927,\n",
       "  0.10035393387079239,\n",
       "  0.09966062009334564,\n",
       "  0.09959762543439865,\n",
       "  0.0993141382932663,\n",
       "  0.0995086207985878,\n",
       "  0.09918674826622009,\n",
       "  0.09912707656621933,\n",
       "  0.10031355172395706,\n",
       "  0.09870179742574692,\n",
       "  0.10003841668367386,\n",
       "  0.09824380278587341,\n",
       "  0.09926360100507736,\n",
       "  0.0983135774731636,\n",
       "  0.09794624894857407,\n",
       "  0.09845075011253357,\n",
       "  0.0975864827632904,\n",
       "  0.09848333895206451,\n",
       "  0.09769874811172485,\n",
       "  0.09892561286687851,\n",
       "  0.09722907096147537,\n",
       "  0.09715956449508667,\n",
       "  0.09768220037221909,\n",
       "  0.09664078801870346,\n",
       "  0.09681636840105057,\n",
       "  0.09662836045026779,\n",
       "  0.09723144769668579,\n",
       "  0.09636291116476059,\n",
       "  0.09741894900798798,\n",
       "  0.09604320675134659,\n",
       "  0.09638221561908722,\n",
       "  0.09605769068002701,\n",
       "  0.09590872377157211,\n",
       "  0.09587211161851883,\n",
       "  0.0957510843873024,\n",
       "  0.09601685404777527,\n",
       "  0.09544496983289719,\n",
       "  0.0956188514828682,\n",
       "  0.09547453373670578,\n",
       "  0.09510177373886108,\n",
       "  0.09489185363054276,\n",
       "  0.09524743258953094,\n",
       "  0.09527569264173508,\n",
       "  0.09481491893529892,\n",
       "  0.09488669037818909,\n",
       "  0.09453662484884262,\n",
       "  0.09479794651269913,\n",
       "  0.09551005810499191,\n",
       "  0.09431803226470947,\n",
       "  0.09463263303041458,\n",
       "  0.09414844214916229,\n",
       "  0.09410924464464188,\n",
       "  0.0938817709684372,\n",
       "  0.09414292126893997,\n",
       "  0.09404365718364716,\n",
       "  0.09383564442396164,\n",
       "  0.09374616295099258,\n",
       "  0.09429618716239929,\n",
       "  0.09332581609487534,\n",
       "  0.093296118080616,\n",
       "  0.09362369775772095,\n",
       "  0.09381535649299622,\n",
       "  0.09300179034471512,\n",
       "  0.09381943196058273,\n",
       "  0.09296532720327377,\n",
       "  0.09290941804647446,\n",
       "  0.09295333176851273,\n",
       "  0.09297950565814972,\n",
       "  0.09295995533466339,\n",
       "  0.09271008521318436,\n",
       "  0.0930183157324791,\n",
       "  0.09253796935081482,\n",
       "  0.09230665862560272,\n",
       "  0.0920884981751442,\n",
       "  0.09228768199682236,\n",
       "  0.09205687046051025,\n",
       "  0.09324052184820175,\n",
       "  0.09213460236787796,\n",
       "  0.09266488254070282,\n",
       "  0.0916568860411644,\n",
       "  0.09186087548732758,\n",
       "  0.09121236205101013,\n",
       "  0.0913558229804039,\n",
       "  0.0912034884095192,\n",
       "  0.09070423245429993,\n",
       "  0.0903661772608757,\n",
       "  0.0900455191731453,\n",
       "  0.09096410870552063,\n",
       "  0.09013774991035461,\n",
       "  0.0904182717204094,\n",
       "  0.08949901908636093,\n",
       "  0.08934775739908218,\n",
       "  0.09087888151407242,\n",
       "  0.08910969644784927,\n",
       "  0.08940684050321579,\n",
       "  0.08911752700805664,\n",
       "  0.08905251324176788,\n",
       "  0.08852492272853851,\n",
       "  0.08889281004667282,\n",
       "  0.0892360731959343,\n",
       "  0.08829578757286072,\n",
       "  0.0887860655784607,\n",
       "  0.08819294720888138,\n",
       "  0.08799152076244354,\n",
       "  0.08793750405311584,\n",
       "  0.08789242804050446,\n",
       "  0.0890025720000267,\n",
       "  0.08734610676765442,\n",
       "  0.0873972475528717,\n",
       "  0.08735276013612747,\n",
       "  0.08692728728055954,\n",
       "  0.08911026269197464,\n",
       "  0.08686447143554688,\n",
       "  0.08674334734678268,\n",
       "  0.08718795329332352,\n",
       "  0.08707525581121445,\n",
       "  0.0866740494966507,\n",
       "  0.08637885004281998,\n",
       "  0.08812441676855087,\n",
       "  0.08621137589216232,\n",
       "  0.08658761531114578,\n",
       "  0.08614174276590347,\n",
       "  0.08593768626451492,\n",
       "  0.08607391268014908,\n",
       "  0.08585851639509201,\n",
       "  0.08619335293769836,\n",
       "  0.08678895980119705,\n",
       "  0.08582258224487305,\n",
       "  0.09140072017908096,\n",
       "  0.0857640877366066,\n",
       "  0.0860045850276947,\n",
       "  0.08496791124343872,\n",
       "  0.08558903634548187,\n",
       "  0.08524191379547119,\n",
       "  0.08560940623283386,\n",
       "  0.08595031499862671,\n",
       "  0.0849994421005249,\n",
       "  0.08500462025403976,\n",
       "  0.08508110046386719,\n",
       "  0.08458244800567627,\n",
       "  0.08505482971668243,\n",
       "  0.08427981287240982,\n",
       "  0.08433668315410614,\n",
       "  0.08448630571365356,\n",
       "  0.0841231495141983,\n",
       "  0.08450524508953094,\n",
       "  0.08480247110128403,\n",
       "  0.0846949890255928,\n",
       "  0.08436909317970276,\n",
       "  0.08397044986486435,\n",
       "  0.08425302058458328,\n",
       "  0.08505642414093018,\n",
       "  0.08390745520591736,\n",
       "  0.0840359702706337,\n",
       "  0.08503943681716919,\n",
       "  0.08446326106786728,\n",
       "  0.0839533880352974,\n",
       "  0.08429771661758423,\n",
       "  0.08374188095331192,\n",
       "  0.08348412066698074,\n",
       "  0.08355183899402618,\n",
       "  0.08441875129938126,\n",
       "  0.08447431027889252,\n",
       "  0.08367554843425751,\n",
       "  0.08452698588371277,\n",
       "  0.08337585628032684,\n",
       "  0.08547993749380112,\n",
       "  0.08357225358486176,\n",
       "  0.08369240164756775,\n",
       "  0.08501773327589035,\n",
       "  0.08335060626268387,\n",
       "  0.08714477717876434,\n",
       "  0.08322634547948837,\n",
       "  0.08336997777223587,\n",
       "  0.0844908356666565,\n",
       "  0.08317895978689194,\n",
       "  0.08391302824020386,\n",
       "  0.0829613134264946,\n",
       "  0.08342818170785904,\n",
       "  0.08358659595251083,\n",
       "  0.0831163302063942,\n",
       "  0.0828477069735527,\n",
       "  0.08435577154159546,\n",
       "  0.0831659734249115,\n",
       "  0.08607108145952225,\n",
       "  0.08320596069097519,\n",
       "  0.08439318090677261,\n",
       "  0.08293798565864563,\n",
       "  0.08304335176944733,\n",
       "  0.08328428119421005,\n",
       "  0.08322571218013763,\n",
       "  0.08720256388187408,\n",
       "  0.08276903629302979,\n",
       "  0.08321604132652283,\n",
       "  0.08345629274845123]}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "abe92f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'root_mean_squared_error', 'val_loss', 'val_root_mean_squared_error'])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5f69f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss = model.history.history['loss']\n",
    "val_loss = model.history.history['val_loss']\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "#plt.ylim([0,500]) #Epoch 300\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train','Val'])\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f0a63b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185</span> (744.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m185\u001b[0m (744.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> (500.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m124\u001b[0m (500.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1b6a217d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13*4 #52+4(bias)=56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cf8aca24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185</span> (744.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m185\u001b[0m (744.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> (500.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m124\u001b[0m (500.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ce4ec",
   "metadata": {},
   "source": [
    "### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9f72ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AE8BCCEFC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "487a4a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.668463  ],\n",
       "       [33.566036  ],\n",
       "       [20.923004  ],\n",
       "       [24.283583  ],\n",
       "       [18.653793  ],\n",
       "       [18.969797  ],\n",
       "       [13.517894  ],\n",
       "       [12.67041   ],\n",
       "       [21.780102  ],\n",
       "       [21.07939   ],\n",
       "       [18.41747   ],\n",
       "       [15.626099  ],\n",
       "       [-6.186539  ],\n",
       "       [19.748356  ],\n",
       "       [18.992805  ],\n",
       "       [20.550686  ],\n",
       "       [17.196508  ],\n",
       "       [ 7.0563617 ],\n",
       "       [34.929382  ],\n",
       "       [18.075886  ],\n",
       "       [33.50121   ],\n",
       "       [30.354622  ],\n",
       "       [ 6.9606204 ],\n",
       "       [21.031181  ],\n",
       "       [18.91299   ],\n",
       "       [16.735722  ],\n",
       "       [24.271421  ],\n",
       "       [13.61068   ],\n",
       "       [16.971277  ],\n",
       "       [20.653404  ],\n",
       "       [20.216854  ],\n",
       "       [24.067736  ],\n",
       "       [20.55671   ],\n",
       "       [23.591522  ],\n",
       "       [15.291557  ],\n",
       "       [17.03732   ],\n",
       "       [26.98115   ],\n",
       "       [27.925476  ],\n",
       "       [18.087412  ],\n",
       "       [21.533573  ],\n",
       "       [11.789173  ],\n",
       "       [31.580986  ],\n",
       "       [37.79233   ],\n",
       "       [15.804943  ],\n",
       "       [23.127129  ],\n",
       "       [18.593533  ],\n",
       "       [12.251845  ],\n",
       "       [22.982395  ],\n",
       "       [18.549477  ],\n",
       "       [29.496908  ],\n",
       "       [20.52737   ],\n",
       "       [34.260174  ],\n",
       "       [13.547845  ],\n",
       "       [28.862558  ],\n",
       "       [34.3145    ],\n",
       "       [19.269623  ],\n",
       "       [19.99364   ],\n",
       "       [34.282246  ],\n",
       "       [26.198149  ],\n",
       "       [11.808791  ],\n",
       "       [23.157923  ],\n",
       "       [35.234867  ],\n",
       "       [29.41449   ],\n",
       "       [10.075394  ],\n",
       "       [26.75283   ],\n",
       "       [12.1035385 ],\n",
       "       [19.12629   ],\n",
       "       [26.505629  ],\n",
       "       [33.320705  ],\n",
       "       [12.937981  ],\n",
       "       [25.947836  ],\n",
       "       [23.864975  ],\n",
       "       [11.341614  ],\n",
       "       [20.873318  ],\n",
       "       [22.81066   ],\n",
       "       [ 3.649284  ],\n",
       "       [22.319738  ],\n",
       "       [37.444477  ],\n",
       "       [15.201324  ],\n",
       "       [15.677078  ],\n",
       "       [20.955494  ],\n",
       "       [11.053341  ],\n",
       "       [21.859583  ],\n",
       "       [11.11042   ],\n",
       "       [23.08081   ],\n",
       "       [29.74049   ],\n",
       "       [18.133667  ],\n",
       "       [24.892857  ],\n",
       "       [27.420101  ],\n",
       "       [20.304375  ],\n",
       "       [22.710562  ],\n",
       "       [ 4.5421596 ],\n",
       "       [21.643353  ],\n",
       "       [14.020392  ],\n",
       "       [22.857723  ],\n",
       "       [22.507523  ],\n",
       "       [24.077557  ],\n",
       "       [-0.19321486],\n",
       "       [13.148857  ],\n",
       "       [11.874687  ],\n",
       "       [24.84401   ],\n",
       "       [23.68164   ],\n",
       "       [10.788044  ],\n",
       "       [21.741632  ],\n",
       "       [18.747007  ],\n",
       "       [ 9.169411  ],\n",
       "       [19.72505   ],\n",
       "       [27.01883   ],\n",
       "       [29.570572  ],\n",
       "       [24.86367   ],\n",
       "       [ 7.297149  ],\n",
       "       [14.485855  ],\n",
       "       [28.429821  ],\n",
       "       [31.816164  ],\n",
       "       [31.691757  ],\n",
       "       [15.977409  ],\n",
       "       [31.29674   ],\n",
       "       [ 9.067944  ],\n",
       "       [23.304995  ],\n",
       "       [24.530237  ],\n",
       "       [18.550865  ],\n",
       "       [24.093966  ],\n",
       "       [ 1.1674342 ],\n",
       "       [22.037378  ],\n",
       "       [30.357622  ],\n",
       "       [22.873314  ],\n",
       "       [26.204142  ],\n",
       "       [31.037008  ],\n",
       "       [16.483677  ],\n",
       "       [32.01377   ],\n",
       "       [ 9.653948  ],\n",
       "       [18.468231  ],\n",
       "       [19.729662  ],\n",
       "       [14.7301655 ],\n",
       "       [ 8.074552  ],\n",
       "       [17.427704  ],\n",
       "       [29.785398  ],\n",
       "       [31.304184  ],\n",
       "       [28.290667  ],\n",
       "       [15.739651  ],\n",
       "       [16.61184   ],\n",
       "       [28.11602   ],\n",
       "       [22.54677   ],\n",
       "       [12.8046055 ],\n",
       "       [ 3.1774554 ],\n",
       "       [22.534657  ],\n",
       "       [20.597717  ],\n",
       "       [16.958332  ],\n",
       "       [12.132054  ],\n",
       "       [37.055313  ],\n",
       "       [16.103989  ],\n",
       "       [18.93851   ],\n",
       "       [28.575262  ],\n",
       "       [20.003939  ],\n",
       "       [27.6607    ],\n",
       "       [21.670868  ],\n",
       "       [13.37709   ],\n",
       "       [25.10244   ],\n",
       "       [31.456783  ],\n",
       "       [ 4.011642  ],\n",
       "       [27.399168  ],\n",
       "       [18.839111  ],\n",
       "       [21.3021    ],\n",
       "       [24.524347  ],\n",
       "       [26.230604  ],\n",
       "       [21.014864  ],\n",
       "       [36.000694  ]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "641298aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.668463] 23.6\n"
     ]
    }
   ],
   "source": [
    "print(pred[0],y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9bc49ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>3.649284</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>4.011642</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>15.677078</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-6.186539</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>3.177455</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>36.000694</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>34.929382</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24.077557</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>37.792332</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>37.055313</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Original\n",
       "398   3.649284       5.0\n",
       "405   4.011642       5.0\n",
       "489  15.677078       7.0\n",
       "414  -6.186539       7.0\n",
       "404   3.177455       8.5\n",
       "..         ...       ...\n",
       "262  36.000694      48.8\n",
       "195  34.929382      50.0\n",
       "371  24.077557      50.0\n",
       "204  37.792332      50.0\n",
       "225  37.055313      50.0\n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_pred_test=pd.DataFrame(data={'Predicted':pred.flatten(),'Original':y_test})\n",
    "combine_pred_test=combine_pred_test.sort_values(by='Original',ascending=True)\n",
    "combine_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3cbb7732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AE932C1260> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ea66fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = scalar.inverse_transform(preds).flatten()\n",
    "actuals = scalar.inverse_transform(y_test.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2648b3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08580280047985551\n"
     ]
    }
   ],
   "source": [
    "mse = (((final_pred-actuals)**2).mean())**0.5\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
